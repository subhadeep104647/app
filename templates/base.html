<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{% block title %}My Website{% end block%}</title>
    <style>
        .body{
             margin: 0;
             font-family: Arial, sans-serif;
             background-image: url("bg.jpg") no-repeat center center/cover;
             height: 100vh;
             display: flex;
             flex-direction: column;
             font-family: Arial, Helvetica, sans-serif;
        }
        .header{
            background-color: aliceblue;
            padding: 10px;
            background: fixed;
        }
        .footer{
            background-color: antiquewhite;
            padding: 10px;
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <header>
        <h2>Zenrider</h2>
        <nev>
            <a href="/">Home</a>
            <a href="/about">About</a>
        </nev>
    </header>
    {% block content %}

    {% end block %}
    <footer>
        <p>The main goal of this Proof of Concept (POC) is to show that it is possible to use AI to monitor a driver's emotional and attentiveness state in real-time with a basic computing device. This POC aims to identify key emotional signals like drowsiness, anger, or distraction by analyzing the driver’s facial expressions through the webcam using computer vision and AI models. When the system detects an unsafe state, it will immediately trigger a voice or text alert to warn the driver to stay alert or calm down. The system can also play music based on the driver’s mood by interpreting their expressions. The driver can use simple voice commands to pause the music, change tracks, or adjust the volume. Additionally, the system will include GPS to detect external traffic and environmental sounds. It can then pause the music or lower the volume based on the driver's preferences.
This project shows how even a simple hardware setup can support life-saving features in smart vehicles using open-source AI tools like OpenCV, DeepFace, and pyttsx3 for voice alerts. This demonstration will confirm the basic functions of the proposed system and serve as the first step toward integrating it into actual in-vehicle platforms in the future.
</p>
    </footer>
</body>
</html>